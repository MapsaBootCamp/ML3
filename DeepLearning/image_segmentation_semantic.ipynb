{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import load_img, img_to_array"
      ],
      "metadata": {
        "id": "W1C60hRMR0T-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIW4RQmONUMc"
      },
      "outputs": [],
      "source": [
        "!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
        "!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
        "!tar -xf images.tar.gz\n",
        "!tar -xf annotations.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "input_dir = \"images/\"\n",
        "target_dir = \"annotations/trimaps/\"\n",
        "\n",
        "input_img_paths = sorted([os.path.join(input_dir, fname) for fname in os.listdir(input_dir) if fname.endswith(\".jpg\")])\n",
        "target_paths = sorted([os.path.join(target_dir, fname) for fname in os.listdir(target_dir) if fname.endswith(\".png\") and not fname.startswith(\".\")])"
      ],
      "metadata": {
        "id": "OVn7IvITN7MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_target(target_array):\n",
        "  normalized_array = (target_array.astype(\"uint8\") - 1) * 127\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(normalized_array[:, :], cmap=\"gray\")\n",
        "\n",
        "img = img_to_array(load_img(target_paths[9], target_size=(200, 200), color_mode=\"grayscale\"))\n",
        "print(img.shape)\n",
        "display_target(img)"
      ],
      "metadata": {
        "id": "UfcXu2acQEMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "img_size = (200, 200)\n",
        "num_imgs = len(input_img_paths)\n",
        "\n",
        "\n",
        "def path_to_input_image(path):\n",
        "  return img_to_array(load_img(path, target_size=img_size))\n",
        "\n",
        "\n",
        "def path_to_target(path):\n",
        "  img = img_to_array(\n",
        "      load_img(path, \n",
        "               target_size=img_size, \n",
        "               color_mode=\"grayscale\"))\n",
        "  img = img.astype(\"uint8\") - 1\n",
        "  return img\n",
        "\n",
        "input_imgs = np.zeros((num_imgs,) + img_size + (3,), dtype=\"float32\")\n",
        "targets = np.zeros((num_imgs,) + img_size + (1,), dtype=\"uint8\")\n",
        "\n",
        "for i in range(num_imgs):\n",
        "  input_imgs[i] = path_to_input_image(input_img_paths[i])\n",
        "  targets[i] = path_to_target(target_paths[i])"
      ],
      "metadata": {
        "id": "z9cB_Nv-RXTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_val_samples = 1000\n",
        "train_input_imgs = input_imgs[:-num_val_samples]\n",
        "train_targets = targets[:-num_val_samples]\n",
        "val_input_imgs = input_imgs[-num_val_samples:]\n",
        "val_targets = targets[-num_val_samples:]"
      ],
      "metadata": {
        "id": "NIsuzdGLX6lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(img_size, num_classes):\n",
        "\n",
        "  inputs = keras.Input(shape=img_size + (3,))\n",
        "  x = layers.Rescaling(1./255)(inputs)\n",
        "  \n",
        "  x = layers.Conv2D(64, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = layers.Conv2D(128, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = layers.Conv2D(256, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "\n",
        "  x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
        "  x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
        "  x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
        "\n",
        "  outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "1B1AvUGjYYif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model(img_size=img_size, num_classes=3)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "eWHiDtF2aCeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"oxford_segmentation.keras\",save_best_only=True)]\n",
        "history = model.fit(train_input_imgs, train_targets, epochs=50, callbacks=callbacks, batch_size=64, validation_data=(val_input_imgs, val_targets))"
      ],
      "metadata": {
        "id": "nQnFnJ4raYtJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}